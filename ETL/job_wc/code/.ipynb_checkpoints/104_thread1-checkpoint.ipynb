{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "wc = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_content(url,lock): #一個用來分析內頁的function\n",
    "    try:\n",
    "        count = 5\n",
    "        while count:\n",
    "            res2 = r.get(url)\n",
    "            if res2.status_code == 200:\n",
    "                soup = BeautifulSoup(res2.text, 'lxml')\n",
    "                lans = soup.select('.tool')[0].select('a')  #lans  is  list\n",
    "        #         print(lans)\n",
    "                global wc\n",
    "                with lock:      \n",
    "                    for lan in lans: \n",
    "                        if lan.text in wc:  \n",
    "                            wc[lan.text] += 1\n",
    "                        else:\n",
    "                            wc[lan.text] = 1\n",
    "            else:\n",
    "                count -= 1\n",
    "                time.sleep(0.5)\n",
    "        time.sleep(0.5)\n",
    "        if count == 0:\n",
    "            fail_links.append(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_threadpool(alinks, lock):\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(grab_content, link, lock) for link in alinks]\n",
    "        print('page is finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pageURL(url, lock):  #找所有連結\n",
    "    alinks = []\n",
    "    \n",
    "    try:\n",
    "        count = 5\n",
    "        while count:\n",
    "            res = r.get(url)\n",
    "            if res.status_code == 200:\n",
    "                soup = BeautifulSoup(res.text, 'lxml')\n",
    "                links = soup.select(\".j_cont > ul > li  > div > a\")\n",
    "                for link in links:\n",
    "                    if(\"jobno\" in link['href']):  \n",
    "                         alinks.append(Host + link['href']) #href put in innerURL function\n",
    "                grab_threadpool(alinks, lock)\n",
    "                break\n",
    "            else:\n",
    "                count -= 1\n",
    "                time.sleep(1)\n",
    "        if count == 0:\n",
    "            fail_pages.append(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GrabLinkThread (threading.Thread): # new MyClass extends Thread  \n",
    "    \n",
    "    def __init__(self, url, lock):   # __init__  is a constructor    #args傳入\n",
    "        super(GrabLinkThread, self).__init__()  #super()  傳到父類別的建構子\n",
    "        self.url = url\n",
    "        self.lock = lock\n",
    "    \n",
    "    def run(self):   #等於java中的run  overwrite  \n",
    "        pageURL(url, self.lock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n",
      "page is finish\n",
      "(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n",
      "\n",
      "\n",
      "\n",
      "(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n",
      "page is finish\n",
      "page is finish\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n",
      "page is finish\n",
      "page is finish\n",
      "page is finish\n",
      "(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n"
     ]
    }
   ],
   "source": [
    "thread_list=[]\n",
    "lock = threading.Lock()\n",
    "wc = Counter()\n",
    "Host = 'https://www.104.com.tw'\n",
    "fail_pages = []   \n",
    "fail_links = []\n",
    "for i in range(1,150):\n",
    "    url =  Host + '/jobbank/joblist/joblist.cfm?jobsource=n104bank1&ro=1&keyword=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E5%B8%AB&order=1&asc=0&page={}'.format(i)\n",
    "    th = GrabLinkThread(url, lock)\n",
    "    th.start()\n",
    "    time.sleep(1)\n",
    "    thread_list.append(th)\n",
    "else:\n",
    "    print('[Debug] all the threads are started !!')\n",
    "for thread in thread_list:\n",
    "    thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(wordCoun.most_common())\n",
    "# lan_csv = df.to_csv('lan.csv')\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCoun\n",
    "wordCoun2=sorted(wordCoun.items(), key=lambda d:d[1], reverse = True)\n",
    "wordCoun2[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
